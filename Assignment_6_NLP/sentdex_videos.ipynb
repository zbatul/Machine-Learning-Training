{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 1 : tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_txt = \"Hello Mr. Smith, how are you doing today? It is good to see you after so long. Get ready by 9:00 AM. We are going to a meeting with Miss. Francis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'It is good to see you after so long.', 'Get ready by 9:00 AM.', 'We are going to a meeting with Miss.', 'Francis.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(example_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'It', 'is', 'good', 'to', 'see', 'you', 'after', 'so', 'long', '.', 'Get', 'ready', 'by', '9:00', 'AM', '.', 'We', 'are', 'going', 'to', 'a', 'meeting', 'with', 'Miss', '.', 'Francis', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(example_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 2 : Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex = \"This is an example sentence for testing stop words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', 'sentence', 'testing', 'stop', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_sentence = []\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', 'sentence', 'testing', 'stop', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "fil_sen = [w for w in words if not w in stop_words]\n",
    "print(fil_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 3 : Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex = [\"python\", \"pythoning\", \"pythoner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "for w in ex:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = \"It is very important to do pythoning while learning python and be pythonly good in it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "veri\n",
      "import\n",
      "to\n",
      "do\n",
      "python\n",
      "while\n",
      "learn\n",
      "python\n",
      "and\n",
      "be\n",
      "pythonli\n",
      "good\n",
      "in\n",
      "it\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 4 : PoS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = state_union.raw(\"2005-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_set = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009965034965034964 0.006688963210702341 0.010145729570190002 5720 299 57 2\n",
      "0.00017482517482517483 0.0033444816053511705 0.0 5720 299 1 1\n",
      "0.0013986013986013986 0.0033444816053511705 0.0012912746725696365 5720 299 8 1\n",
      "0.001048951048951049 0.0033444816053511705 0.0009223390518354548 5720 299 6 1\n",
      "0.0012237762237762239 0.016722408026755852 0.00036893562073418186 5720 299 7 5\n",
      "0.04020979020979021 0.07357859531772576 0.03836930455635491 5720 299 230 22\n",
      "0.00017482517482517483 0.0033444816053511705 0.0 5720 299 1 1\n",
      "0.0015734265734265735 0.006688963210702341 0.0012912746725696365 5720 299 9 2\n",
      "0.00017482517482517483 0.0033444816053511705 0.0 5720 299 1 1\n",
      "0.0026223776223776225 0.010033444816053512 0.002213613724405091 5720 299 15 3\n",
      "0.00017482517482517483 0.0033444816053511705 0.0 5720 299 1 1\n",
      "0.0008741258741258741 0.006688963210702341 0.0005534034311012728 5720 299 5 2\n",
      "0.0022727272727272726 0.0033444816053511705 0.002213613724405091 5720 299 13 1\n",
      "0.003146853146853147 0.013377926421404682 0.002582549345139273 5720 299 18 4\n",
      "0.0013986013986013986 0.0033444816053511705 0.0012912746725696365 5720 299 8 1\n",
      "0.003146853146853147 0.006688963210702341 0.002951484965873455 5720 299 18 2\n",
      "0.0024475524475524478 0.006688963210702341 0.002213613724405091 5720 299 14 2\n",
      "0.0015734265734265735 0.0033444816053511705 0.0014757424829367274 5720 299 9 1\n",
      "0.0019230769230769232 0.0033444816053511705 0.0018446781036709095 5720 299 11 1\n",
      "0.0006993006993006993 0.0033444816053511705 0.0005534034311012728 5720 299 4 1\n",
      "0.0008741258741258741 0.006688963210702341 0.0005534034311012728 5720 299 5 2\n",
      "0.001048951048951049 0.013377926421404682 0.00036893562073418186 5720 299 6 4\n",
      "0.015559440559440559 0.0033444816053511705 0.016233167312304002 5720 299 89 1\n",
      "0.002972027972027972 0.0033444816053511705 0.002951484965873455 5720 299 17 1\n",
      "0.0006993006993006993 0.0033444816053511705 0.0005534034311012728 5720 299 4 1\n",
      "0.00034965034965034965 0.0033444816053511705 0.00018446781036709093 5720 299 2 1\n",
      "0.0038461538461538464 0.006688963210702341 0.003689356207341819 5720 299 22 2\n",
      "0.0024475524475524478 0.0033444816053511705 0.002398081534772182 5720 299 14 1\n",
      "0.00034965034965034965 0.0033444816053511705 0.00018446781036709093 5720 299 2 1\n",
      "0.00017482517482517483 0.0033444816053511705 0.0 5720 299 1 1\n",
      "0.0024475524475524478 0.016722408026755852 0.0016602102933038186 5720 299 14 5\n",
      "0.00017482517482517483 0.0033444816053511705 0.0 5720 299 1 1\n",
      "0.0008741258741258741 0.006688963210702341 0.0005534034311012728 5720 299 5 2\n",
      "0.0013986013986013986 0.0033444816053511705 0.0012912746725696365 5720 299 8 1\n",
      "0.017132867132867134 0.04013377926421405 0.01586423169156982 5720 299 98 12\n",
      "0.013111888111888112 0.010033444816053512 0.013281682346430549 5720 299 75 3\n",
      "0.00017482517482517483 0.0033444816053511705 0.0 5720 299 1 1\n",
      "0.00034965034965034965 0.0033444816053511705 0.00018446781036709093 5720 299 2 1\n",
      "0.0034965034965034965 0.0033444816053511705 0.003504888396974728 5720 299 20 1\n",
      "0.004370629370629371 0.0033444816053511705 0.004427227448810182 5720 299 25 1\n",
      "0.04493006993006993 0.043478260869565216 0.04501014572957019 5720 299 257 13\n",
      "0.0012237762237762239 0.006688963210702341 0.0009223390518354548 5720 299 7 2\n",
      "0.0005244755244755245 0.0033444816053511705 0.00036893562073418186 5720 299 3 1\n",
      "0.006118881118881119 0.0033444816053511705 0.006271905552481092 5720 299 35 1\n",
      "0.003146853146853147 0.0033444816053511705 0.003135952776240546 5720 299 18 1\n",
      "0.029545454545454545 0.006688963210702341 0.030806124331304186 5720 299 169 2\n",
      "0.00034965034965034965 0.006688963210702341 0.0 5720 299 2 2\n",
      "0.016258741258741258 0.0802675585284281 0.012728278915329275 5720 299 93 24\n",
      "0.0005244755244755245 0.006688963210702341 0.00018446781036709093 5720 299 3 2\n",
      "0.001048951048951049 0.0033444816053511705 0.0009223390518354548 5720 299 6 1\n",
      "0.005944055944055944 0.026755852842809364 0.004796163069544364 5720 299 34 8\n",
      "0.005244755244755245 0.006688963210702341 0.005165098690278546 5720 299 30 2\n",
      "0.0022727272727272726 0.0033444816053511705 0.002213613724405091 5720 299 13 1\n",
      "0.0015734265734265735 0.0033444816053511705 0.0014757424829367274 5720 299 9 1\n",
      "0.004370629370629371 0.0033444816053511705 0.004427227448810182 5720 299 25 1\n",
      "0.01381118881118881 0.020066889632107024 0.013466150156797639 5720 299 79 6\n"
     ]
    }
   ],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized = custom_sent_tokenizer.tokenize(sample_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_pos():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "process_pos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 5 : Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_chunk():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunk = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP><NN>?}\"\"\"\n",
    "            chunk_parser = nltk.RegexpParser(chunk)\n",
    "            chunked = chunk_parser.parse(tagged)\n",
    "            print(chunked)\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk PRESIDENT/NNP)\n",
      "  (Chunk GEORGE/NNP)\n",
      "  (Chunk W./NNP)\n",
      "  (Chunk BUSH/NNP)\n",
      "  'S/POS\n",
      "  (Chunk ADDRESS/NNP)\n",
      "  BEFORE/IN\n",
      "  (Chunk A/NNP)\n",
      "  (Chunk JOINT/NNP)\n",
      "  (Chunk SESSION/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP)\n",
      "  (Chunk CONGRESS/NNP)\n",
      "  (Chunk ON/NNP)\n",
      "  (Chunk THE/NNP)\n",
      "  (Chunk STATE/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP)\n",
      "  (Chunk UNION/NNP)\n",
      "  (Chunk January/NNP)\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  (Chunk THE/NNP)\n",
      "  (Chunk PRESIDENT/NNP)\n",
      "  :/:\n",
      "  (Chunk Thank/NNP)\n",
      "  you/PRP\n",
      "  all/DT\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk Mr./NNP)\n",
      "  (Chunk Speaker/NNP)\n",
      "  ,/,\n",
      "  (Chunk Vice/NNP)\n",
      "  (Chunk President/NNP)\n",
      "  (Chunk Cheney/NNP)\n",
      "  ,/,\n",
      "  members/NNS\n",
      "  of/IN\n",
      "  (Chunk Congress/NNP)\n",
      "  ,/,\n",
      "  members/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk Supreme/NNP)\n",
      "  (Chunk Court/NNP)\n",
      "  and/CC\n",
      "  diplomatic/JJ\n",
      "  corps/NN\n",
      "  ,/,\n",
      "  distinguished/JJ\n",
      "  guests/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  :/:\n",
      "  Today/VB\n",
      "  our/PRP$\n",
      "  nation/NN\n",
      "  lost/VBD\n",
      "  a/DT\n",
      "  beloved/VBN\n",
      "  ,/,\n",
      "  graceful/JJ\n",
      "  ,/,\n",
      "  courageous/JJ\n",
      "  woman/NN\n",
      "  who/WP\n",
      "  (Chunk called/VBD America/NNP)\n",
      "  to/TO\n",
      "  its/PRP$\n",
      "  founding/NN\n",
      "  ideals/NNS\n",
      "  and/CC\n",
      "  carried/VBD\n",
      "  on/IN\n",
      "  a/DT\n",
      "  noble/JJ\n",
      "  dream/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Tonight/NN\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  comforted/VBN\n",
      "  by/IN\n",
      "  the/DT\n",
      "  hope/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  glad/JJ\n",
      "  reunion/NN\n",
      "  with/IN\n",
      "  the/DT\n",
      "  husband/NN\n",
      "  who/WP\n",
      "  was/VBD\n",
      "  taken/VBN\n",
      "  so/RB\n",
      "  long/RB\n",
      "  ago/RB\n",
      "  ,/,\n",
      "  and/CC\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  grateful/JJ\n",
      "  for/IN\n",
      "  the/DT\n",
      "  good/JJ\n",
      "  life/NN\n",
      "  of/IN\n",
      "  (Chunk Coretta/NNP)\n",
      "  (Chunk Scott/NNP)\n",
      "  (Chunk King/NNP)\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  (Chunk President/NNP)\n",
      "  (Chunk George/NNP)\n",
      "  (Chunk W./NNP)\n",
      "  (Chunk Bush/NNP)\n",
      "  reacts/VBZ\n",
      "  to/TO\n",
      "  applause/VB\n",
      "  during/IN\n",
      "  his/PRP$\n",
      "  (Chunk State/NNP)\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk Union/NNP)\n",
      "  (Chunk Address/NNP)\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (Chunk Capitol/NNP)\n",
      "  ,/,\n",
      "  (Chunk Tuesday/NNP)\n",
      "  ,/,\n",
      "  (Chunk Jan/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "process_chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 6 : Chinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_chink():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunk = r\"\"\"Chunk: {<.*>+}\n",
    "                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "            chunk_parser = nltk.RegexpParser(chunk)\n",
    "            chunked = chunk_parser.parse(tagged)\n",
    "            print(chunked)\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP 'S/POS ADDRESS/NNP)\n",
      "  BEFORE/IN\n",
      "  (Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "  OF/IN\n",
      "  (Chunk\n",
      "    THE/NNP\n",
      "    UNION/NNP\n",
      "    January/NNP\n",
      "    31/CD\n",
      "    ,/,\n",
      "    2006/CD\n",
      "    THE/NNP\n",
      "    PRESIDENT/NNP\n",
      "    :/:\n",
      "    Thank/NNP\n",
      "    you/PRP)\n",
      "  all/DT\n",
      "  (Chunk ./.))\n",
      "(S\n",
      "  (Chunk\n",
      "    Mr./NNP\n",
      "    Speaker/NNP\n",
      "    ,/,\n",
      "    Vice/NNP\n",
      "    President/NNP\n",
      "    Cheney/NNP\n",
      "    ,/,\n",
      "    members/NNS)\n",
      "  of/IN\n",
      "  (Chunk Congress/NNP ,/, members/NNS)\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk\n",
      "    Supreme/NNP\n",
      "    Court/NNP\n",
      "    and/CC\n",
      "    diplomatic/JJ\n",
      "    corps/NN\n",
      "    ,/,\n",
      "    distinguished/JJ\n",
      "    guests/NNS\n",
      "    ,/,\n",
      "    and/CC\n",
      "    fellow/JJ\n",
      "    citizens/NNS\n",
      "    :/:)\n",
      "  Today/VB\n",
      "  (Chunk our/PRP$ nation/NN)\n",
      "  lost/VBD\n",
      "  a/DT\n",
      "  beloved/VBN\n",
      "  (Chunk ,/, graceful/JJ ,/, courageous/JJ woman/NN who/WP)\n",
      "  called/VBD\n",
      "  (Chunk America/NNP)\n",
      "  to/TO\n",
      "  (Chunk its/PRP$ founding/NN ideals/NNS and/CC)\n",
      "  carried/VBD\n",
      "  on/IN\n",
      "  a/DT\n",
      "  (Chunk noble/JJ dream/NN ./.))\n",
      "(S\n",
      "  (Chunk Tonight/NN we/PRP)\n",
      "  are/VBP\n",
      "  comforted/VBN\n",
      "  by/IN\n",
      "  the/DT\n",
      "  (Chunk hope/NN)\n",
      "  of/IN\n",
      "  a/DT\n",
      "  (Chunk glad/JJ reunion/NN)\n",
      "  with/IN\n",
      "  the/DT\n",
      "  (Chunk husband/NN who/WP)\n",
      "  was/VBD\n",
      "  taken/VBN\n",
      "  (Chunk so/RB long/RB ago/RB ,/, and/CC we/PRP)\n",
      "  are/VBP\n",
      "  (Chunk grateful/JJ)\n",
      "  for/IN\n",
      "  the/DT\n",
      "  (Chunk good/JJ life/NN)\n",
      "  of/IN\n",
      "  (Chunk Coretta/NNP Scott/NNP King/NNP ./.))\n",
      "(S (Chunk (/( Applause/NNP ./. )/)))\n",
      "(S\n",
      "  (Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
      "  reacts/VBZ\n",
      "  to/TO\n",
      "  applause/VB\n",
      "  during/IN\n",
      "  (Chunk his/PRP$ State/NNP)\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk Union/NNP Address/NNP)\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (Chunk Capitol/NNP ,/, Tuesday/NNP ,/, Jan/NNP ./.))\n"
     ]
    }
   ],
   "source": [
    "process_chink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 7 : Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_ner():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged)#, binary=True)\n",
    "            print(namedEnt)\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  PRESIDENT/NNP\n",
      "  (PERSON GEORGE/NNP W./NNP BUSH/NNP)\n",
      "  'S/POS\n",
      "  (ORGANIZATION ADDRESS/NNP)\n",
      "  BEFORE/IN\n",
      "  A/NNP\n",
      "  (ORGANIZATION JOINT/NNP)\n",
      "  SESSION/NNP\n",
      "  OF/IN\n",
      "  (ORGANIZATION THE/NNP)\n",
      "  (ORGANIZATION CONGRESS/NNP)\n",
      "  ON/NNP\n",
      "  THE/NNP\n",
      "  (ORGANIZATION STATE/NNP OF/IN)\n",
      "  (ORGANIZATION THE/NNP)\n",
      "  (ORGANIZATION UNION/NNP)\n",
      "  January/NNP\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  (ORGANIZATION THE/NNP)\n",
      "  PRESIDENT/NNP\n",
      "  :/:\n",
      "  Thank/NNP\n",
      "  you/PRP\n",
      "  all/DT\n",
      "  ./.)\n",
      "(S\n",
      "  (PERSON Mr./NNP Speaker/NNP)\n",
      "  ,/,\n",
      "  Vice/NNP\n",
      "  President/NNP\n",
      "  (PERSON Cheney/NNP)\n",
      "  ,/,\n",
      "  members/NNS\n",
      "  of/IN\n",
      "  (ORGANIZATION Congress/NNP)\n",
      "  ,/,\n",
      "  members/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Supreme/NNP Court/NNP)\n",
      "  and/CC\n",
      "  diplomatic/JJ\n",
      "  corps/NN\n",
      "  ,/,\n",
      "  distinguished/JJ\n",
      "  guests/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  :/:\n",
      "  Today/VB\n",
      "  our/PRP$\n",
      "  nation/NN\n",
      "  lost/VBD\n",
      "  a/DT\n",
      "  beloved/VBN\n",
      "  ,/,\n",
      "  graceful/JJ\n",
      "  ,/,\n",
      "  courageous/JJ\n",
      "  woman/NN\n",
      "  who/WP\n",
      "  called/VBD\n",
      "  (GPE America/NNP)\n",
      "  to/TO\n",
      "  its/PRP$\n",
      "  founding/NN\n",
      "  ideals/NNS\n",
      "  and/CC\n",
      "  carried/VBD\n",
      "  on/IN\n",
      "  a/DT\n",
      "  noble/JJ\n",
      "  dream/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Tonight/NN\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  comforted/VBN\n",
      "  by/IN\n",
      "  the/DT\n",
      "  hope/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  glad/JJ\n",
      "  reunion/NN\n",
      "  with/IN\n",
      "  the/DT\n",
      "  husband/NN\n",
      "  who/WP\n",
      "  was/VBD\n",
      "  taken/VBN\n",
      "  so/RB\n",
      "  long/RB\n",
      "  ago/RB\n",
      "  ,/,\n",
      "  and/CC\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  grateful/JJ\n",
      "  for/IN\n",
      "  the/DT\n",
      "  good/JJ\n",
      "  life/NN\n",
      "  of/IN\n",
      "  (ORGANIZATION Coretta/NNP Scott/NNP King/NNP)\n",
      "  ./.)\n",
      "(S (/( (ORGANIZATION Applause/NNP) ./. )/))\n",
      "(S\n",
      "  President/NNP\n",
      "  (PERSON George/NNP W./NNP Bush/NNP)\n",
      "  reacts/VBZ\n",
      "  to/TO\n",
      "  applause/VB\n",
      "  during/IN\n",
      "  his/PRP$\n",
      "  State/NNP\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Union/NNP Address/NNP)\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (GPE Capitol/NNP)\n",
      "  ,/,\n",
      "  Tuesday/NNP\n",
      "  ,/,\n",
      "  (PERSON Jan/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "process_ner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 8 : Lemmetizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(lem.lemmatize(\"cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n"
     ]
    }
   ],
   "source": [
    "print(lem.lemmatize(\"cacti\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n"
     ]
    }
   ],
   "source": [
    "print(lem.lemmatize(\"better\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "print(lem.lemmatize(\"better\", pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lem.lemmatize(\"run\", pos='a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 9 : NLTK Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_corp = gutenberg.raw(\"bible-kjv.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok = sent_tokenize(sample_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1:5 And God called the light Day, and the darkness he called Night.', 'And the evening and the morning were the first day.', '1:6 And God said, Let there be a firmament in the midst of the waters,\\nand let it divide the waters from the waters.', '1:7 And God made the firmament, and divided the waters which were\\nunder the firmament from the waters which were above the firmament:\\nand it was so.', '1:8 And God called the firmament Heaven.', 'And the evening and the\\nmorning were the second day.', '1:9 And God said, Let the waters under the heaven be gathered together\\nunto one place, and let the dry land appear: and it was so.', '1:10 And God called the dry land Earth; and the gathering together of\\nthe waters called he Seas: and God saw that it was good.', '1:11 And God said, Let the earth bring forth grass, the herb yielding\\nseed, and the fruit tree yielding fruit after his kind, whose seed is\\nin itself, upon the earth: and it was so.', '1:12 And the earth brought forth grass, and herb yielding seed after\\nhis kind, and the tree yielding fruit, whose seed was in itself, after\\nhis kind: and God saw that it was good.']\n"
     ]
    }
   ],
   "source": [
    "print(tok[5:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 10 : WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sysns = wordnet.synsets(\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('plan.n.01'), Synset('program.n.02'), Synset('broadcast.n.02'), Synset('platform.n.02'), Synset('program.n.05'), Synset('course_of_study.n.01'), Synset('program.n.07'), Synset('program.n.08'), Synset('program.v.01'), Synset('program.v.02')]\n"
     ]
    }
   ],
   "source": [
    "print(sysns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('plan.n.01.plan'), Lemma('plan.n.01.program'), Lemma('plan.n.01.programme')]\n"
     ]
    }
   ],
   "source": [
    "print(sysns[0].lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('plan.n.01.plan')\n"
     ]
    }
   ],
   "source": [
    "print(sysns[0].lemmas()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n"
     ]
    }
   ],
   "source": [
    "print(sysns[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a series of steps to be carried out or goals to be accomplished\n"
     ]
    }
   ],
   "source": [
    "print(sysns[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
     ]
    }
   ],
   "source": [
    "print(sysns[0].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synonym = []\n",
    "antonym = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNONYMS : {'respectable', 'unspoiled', 'dear', 'honorable', 'secure', 'soundly', 'proficient', 'ripe', 'near', 'honest', 'expert', 'practiced', 'in_force', 'full', 'well', 'just', 'upright', 'skillful', 'right', 'good', 'sound', 'skilful', 'trade_good', 'estimable', 'commodity', 'effective', 'serious', 'adept', 'goodness', 'salutary', 'unspoilt', 'thoroughly', 'in_effect', 'safe', 'dependable', 'beneficial', 'undecomposed'}\n",
      "ANTONYMS : {'bad', 'evilness', 'ill', 'badness', 'evil'}\n"
     ]
    }
   ],
   "source": [
    "for sysns in wordnet.synsets(\"good\"):\n",
    "    for l in sysns.lemmas():\n",
    "        synonym.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonym.append(l.antonyms()[0].name())\n",
    "print(\"SYNONYMS : \"+str(set(synonym)))\n",
    "print(\"ANTONYMS : \"+str(set(antonym)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Semantic similarity\n",
    "w1 = wordnet.synset(\"ship.n.01\")\n",
    "w2 = wordnet.synset(\"boat.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w3 = wordnet.synset(\"cat.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "print(w1.wup_similarity(w3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 11 : Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = [(list(movie_reviews.words(fileids)), category) for category in movie_reviews.categories() for fileids in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['woody', 'allen', 'is', 'one', 'of', 'the', 'most', 'successful', 'artist', '-', 'directors', 'in', 'hollywood', ',', 'but', 'he', 'is', 'becoming', 'less', 'and', 'less', 'reliable', 'as', 'a', 'filmmaker', '.', 'in', 'his', 'early', 'years', 'of', 'film', '-', 'making', 'he', 'mastered', 'the', 'simple', 'comedy', '.', 'from', 'there', 'he', 'went', 'into', 'a', 'second', 'phase', 'and', 'took', 'risks', 'experimenting', 'with', 'different', 'approaches', 'and', 'styles', '.', 'some', 'of', 'these', 'work', 'better', 'than', 'others', '.', 'zelig', 'and', 'crimes', 'and', 'misdemeanors', 'are', 'the', 'work', 'of', 'a', 'creative', 'and', 'intelligent', 'artist', '.', 'deconstructing', 'harry', 'goes', 'to', 'the', 'other', 'extreme', 'and', 'is', 'a', 'bizarre', 'experiment', 'demanding', 'more', 'of', 'the', 'viewer', 'than', 'it', 'gives', 'back', '.', 'harry', 'block', '(', 'allen', ')', 'has', 'in', 'his', 'life', 'only', 'two', 'drives', '.', 'he', 'wants', 'to', 'have', 'sex', 'with', 'as', 'many', 'women', 'as', 'possible', 'and', 'when', 'he', 'makes', 'a', 'mess', 'of', 'his', 'life', 'and', 'those', 'of', 'his', 'lovers', 'he', 'wants', 'to', 'retreat', 'into', 'his', 'writing', '.', 'the', 'story', 'of', 'this', 'static', 'and', 'highly', 'unsympathetic', 'character', 'is', 'told', 'with', 'a', 'number', 'of', 'often', 'clumsy', 'stylistic', 'experiments', '.', 'perhaps', 'the', 'most', 'irritating', 'device', 'is', 'to', 'express', 'the', 'disjointedness', 'of', 'harry', \"'\", 's', 'life', 'by', 'editing', 'harry', \"'\", 's', 'scenes', 'putting', 'in', 'cuts', 'in', 'the', 'middle', 'as', 'if', 'to', 'show', 'missing', 'time', 'with', 'something', 'edited', 'out', '.', 'as', 'a', 'writer', ',', 'harry', 'puts', 'his', 'friends', 'into', 'his', 'books', 'in', 'the', 'thinnest', 'of', 'disguises', '.', 'the', 'film', 'dramatizes', 'incidents', 'from', 'these', 'supposed', 'books', 'and', 'cuts', 'between', 'his', 'real', 'story', 'line', 'and', 'fragments', 'from', 'harry', \"'\", 's', 'books', 'with', 'different', 'actors', 'playing', 'the', 'real', 'and', 'fictional', 'people', 'in', 'harry', \"'\", 's', 'life', '.', 'these', 'fragments', 'are', 'frustrating', 'in', 'their', 'lack', 'of', 'completion', ',', 'but', 'even', 'more', 'frustrating', 'is', 'the', 'bringing', 'of', 'the', 'characters', 'out', 'of', 'the', 'fragments', 'into', 'scenes', 'with', 'the', 'real', 'characters', '.', 'it', 'is', 'up', 'to', 'the', 'viewer', 'to', 'keep', 'track', 'not', 'just', 'who', 'is', 'fictional', 'and', 'who', 'is', 'real', 'but', 'also', 'to', 'keep', 'straight', 'who', 'is', 'the', 'fictional', 'doppelganger', 'of', 'which', 'real', 'person', '.', 'if', 'that', 'sounds', 'complicated', ',', 'it', 'is', '.', 'then', 'as', 'another', 'device', 'in', 'one', 'of', 'the', 'stories', ',', 'an', 'actor', 'seems', 'to', 'have', 'the', 'peculiar', 'property', 'that', 'he', 'has', 'gone', 'out', 'of', 'focus', 'and', 'can', 'only', 'be', 'seen', 'in', 'blurry', 'image', '.', 'harry', 'sees', 'this', 'as', 'a', 'metaphor', 'for', 'his', 'own', 'condition', 'and', 'himself', 'goes', 'blurry', 'for', 'a', 'short', 'time', '.', 'as', 'if', 'these', 'touches', 'did', 'not', 'create', 'sufficient', 'confusion', ',', 'the', 'story', 'is', 'told', 'out', 'of', 'chronological', 'order', '.', 'if', 'allen', 'were', 'giving', 'the', 'audience', 'a', 'story', 'that', 'was', 'worth', 'decoding', ',', 'any', 'and', 'all', 'of', 'these', 'stylistic', 'touches', 'could', 'be', 'excusable', '.', 'but', 'allen', 'puts', 'the', 'audience', 'through', 'all', 'of', 'this', 'to', 'give', 'us', 'a', 'portrait', 'of', 'harry', 'block', 'who', 'is', 'a', 'selfish', 'manipulator', 'who', 'is', 'not', 'worth', 'the', 'effort', 'to', 'understand', '.', 'deconstructing', 'harry', 'is', 'set', 'at', 'a', 'time', 'when', 'harry', \"'\", 's', 'old', 'college', ',', 'the', 'one', 'that', 'expelled', 'him', 'when', 'he', 'attended', 'it', ',', 'wants', 'now', 'to', 'honor', 'him', 'for', 'a', 'lifetime', 'of', 'writing', 'achievement', '.', 'harry', 'is', 'searching', 'among', 'his', 'friends', 'to', 'find', 'one', 'who', 'will', 'go', 'with', 'him', '.', 'just', 'why', 'someone', 'who', 'is', 'so', 'unwilling', 'to', 'commit', 'to', 'a', 'relationship', 'with', 'anyone', 'suddenly', 'needs', 'the', 'support', 'of', 'someone', 'else', 'is', 'unclear', '.', 'harry', 'tries', 'his', 'current', 'girl', 'friend', 'fay', '(', 'elizabeth', 'shue', ')', 'only', 'to', 'find', 'that', 'she', 'is', 'about', 'to', 'marry', 'harry', \"'\", 's', 'old', 'friend', 'larry', '(', 'billy', 'crystal', ')', '.', 'block', 'would', 'like', 'his', 'son', 'hilly', '(', 'eric', 'lloyd', ')', 'to', 'accompany', 'him', ',', 'but', 'hilly', \"'\", 's', 'mother', ',', 'previously', 'first', 'harry', \"'\", 's', 'psychiatrist', 'and', 'more', 'recently', 'his', 'wife', ',', 'refuses', 'to', 'let', 'her', 'son', 'see', 'his', 'father', '.', 'another', 'friend', 'richard', '(', 'bob', 'balaban', ')', 'would', 'go', 'but', 'has', 'health', 'problems', '.', 'harry', 'also', 'considers', 'bringing', 'a', 'prostitute', 'cookie', '(', 'hazel', 'goodman', ')', '.', 'it', 'is', 'interesting', 'that', 'allen', 'should', 'introduce', 'another', 'likable', 'prostitute', 'so', 'soon', 'after', 'mighty', 'aphrodite', ',', 'but', 'cookie', 'is', 'considerably', 'different', '--', 'black', 'and', 'a', 'lot', 'brighter', 'than', 'mira', 'sorvino', \"'\", 's', 'character', 'in', 'the', 'previous', 'film', '.', 'while', 'the', 'comedy', 'sequences', 'are', 'never', 'complete', ',', 'a', 'few', 'are', 'elaborate', 'and', 'some', 'quite', 'funny', '.', 'the', 'centerpiece', 'of', 'the', 'film', 'is', 'a', 'journey', 'into', 'hell', 'with', 'allen', 'playing', 'a', 'sort', 'of', 'orpheus', 'rescuing', 'fay', 'from', 'the', 'clutches', 'of', 'the', 'devil', ',', 'who', 'looks', 'a', 'lot', 'like', 'larry', '.', 'that', 'story', 'also', 'is', 'left', 'uncompleted', ',', 'perhaps', 'to', 'show', 'harry', \"'\", 's', 'unwillingness', 'to', 'commit', 'even', 'to', 'telling', 'a', 'story', '.', 'the', 'linchpin', 'that', 'was', 'needed', 'to', 'tie', 'together', 'the', 'stylistic', 'quirks', 'of', 'this', 'film', 'was', 'a', 'central', 'character', 'who', 'changes', 'and', 'who', 'gives', 'us', 'something', 'about', 'which', 'to', 'care', '.', 'that', 'character', 'is', 'patently', 'not', 'the', 'one', 'allen', 'creates', 'in', 'harry', 'block', 'and', 'not', 'the', 'characters', 'around', 'harry', 'as', 'seen', 'through', 'his', 'acerbic', 'eyes', '.', 'allen', 'can', 'do', 'much', 'better', 'than', 'deconstructing', 'harry', '.', 'i', 'rate', 'it', 'a', '3', 'on', 'the', '0', 'to', '10', 'scale', 'and', 'a', '-', '1', 'on', 'the', '-', '4', 'to', '+', '4', 'scale', '.'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n"
     ]
    }
   ],
   "source": [
    "print(all_words.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "print(all_words[\"stupid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 12 : Words as features for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(doc):\n",
    "    words = set(doc)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pinter': False, 'jeanine': False, 'barreled': False, 'lowers': False, 'unmistakeable': False, 'smug': False, 'castro': False, 'nuts': False, 'flicks': True, 'eighth': False, 'represents': False, 'concede': False, 'orient': False, 'ws': False, 'sonnenfelds': False, 'souk': False, 'tinder': False, 'engagements': False, 'conehead': False, 'harming': False, 'accessorize': False, 'ratchets': False, 'langella': False, 'comfortably': False, 'weightiness': False, 'ditzism': False, 'thelma': False, 'kotto': False, 'escapades': False, 'damed': False, 'unpleasantness': False, 'rhythms': False, 'sheila': False, 'saunders': False, 'popitti': False, 'reshoot': False, '48': False, 'attractively': False, 'otherness': False, 'roads': False, 'notables': False, 'thrillerism': False, 'mindlessness': False, 'apparatus': False, 'unwanted': False, 'sorossy': False, 'millimeter': False, 'fluffy': False, 'mediciney': False, 'jointly': False, 'nora': False, 'gobbledegook': False, 'takehiro': False, 'tightly': False, 'copper': False, 'vegetative': False, 'gloomily': False, 'medgar': False, 'gregory': False, 'litten': False, 'eatery': False, 'lewis': False, 'participate': False, 'strode': False, 'autocrat': False, 'direction': False, 'gatewood': False, 'propels': False, 'fears': False, '_saturday_night_live_': False, 'tenseness': False, 'corniness': False, 'flows': False, 'dunmore': False, 'unselfconsciously': False, 'koepp': False, 'renny': False, 'fords': False, 'vacuous': False, 'lucidity': False, 'indemnity': False, 'elloquently': False, 'treatise': False, 'slope': False, 'combined': False, 'spaceballs': False, 'bribing': False, 'implied': False, 'arbiters': False, 'strategies': False, 'destruction': False, 'snore': False, 'centerpieces': False, 'chambermaid': False, 'addam': False, 'naivete': False, 'alluded': False, 'rent': False, 'stuntman': False, 'sassy': False, 'nickelodeon': False, 'selves': False, 'trash': False, 'fugitives': False, 'quirkily': False, 'silly': False, 'prostitution': False, 'labored': False, 'anthropologist': False, 'vikings': False, 'lobotomized': False, 'noirs': False, 'verber': False, 'caravaggio': False, 'upgrades': False, 'tilting': False, 'fonz': False, 'portait': False, 'recieve': False, 'snicker': False, 'strived': False, 'reaching': False, 'keanu': False, 'decter': False, 'capitalizes': False, 'capital': False, 'nauseum': False, 'libel': False, 'whistle': False, 'guard': False, 'braeden': False, 'enhancer': False, 'healy': False, 'flaunt': False, 'edtv': False, 'lighten': False, 'gotta': False, 'nostalgics': False, 'prefers': False, 'bernstein': False, 'seek': False, 'tune': False, 'fulcrum': False, 'publically': False, 'wyat': False, 'marble': False, 'sympathetically': False, 'endangered': False, 'mainstay': False, 'dare': False, 'bumcheeks': False, 'oftentimes': False, 'quanq': False, 'deviously': False, 'harrigan': False, 'potente': False, 'quit': False, 'encounter': False, 'spiked': False, 'pears': False, 'adherents': False, 'flaring': False, 'barring': False, 'mysterty': False, 'desiring': False, 'campaigns': False, 'forgets': False, 'cheapo': False, 'hockney': False, 'sentenced': False, 'resembling': False, 'holler': False, 'collector': False, 'malka': False, 'belief': False, 'joaquin': False, 'vanity': False, 'macnamara': False, 'braggarts': False, 'mermaid': False, 'dewayne': False, '2099': False, 'overuses': False, 'tightened': False, 'spins': False, 'interested': False, 'nosferatu': False, 'schlubby': False, 'breed': False, 'spinosauraus': False, '1': False, 'jawa': False, 'encounters': False, 'classy': False, 'alanis': False, 'insinuating': False, 'muppets': False, 'interest': False, 'costs': False, 'baluyev': False, 'premature': False, 'greenstreet': False, 'sidesplitting': False, 'chipmunk': False, 'roxanne': False, 'ranchers': False, 'shuffled': False, 'troy': False, 'pisspoor': False, 'rebounding': False, 'processors': False, 'nerdy': False, 'september': False, 'appalls': False, 'stole': False, 'white': False, 'ustinov': False, 'ceo': False, 'habits': False, 'selena': False, 'bonet': False, 'giveaways': False, '_': False, 'prisoner': False, 'radford': False, 'laments': False, 'skimming': False, 'strains': False, 'unambiguously': False, 'opinions': False, 'ramblings': False, 'enchilada': False, 'acceptance': False, 'grubby': False, 'tian': False, 'regicide': False, 'dissects': False, 'ledoyen': False, 'outre': False, 'grouped': False, 'tangling': False, 'gaynor': False, 'myagi': False, 'trail': False, 'hana': False, 'fargo': False, 'standardly': False, 'rapidity': False, 'injections': False, 'underpaying': False, 'jolting': False, 'penalty': False, 'schemers': False, 'nookie': False, 'pickering': False, 'deviates': False, 'immoral': False, 'eggs': False, 'skateboarder': False, 'butte': False, 'innocent': False, 'orchestrated': False, 'fraud': False, 'underground': False, 'snappiness': False, 'carping': False, 'lifter': False, 'traffiking': False, 'bench': False, 'barred': False, 'defect': False, 'eyebrows': False, 'reign': False, 'mirth': False, 'solid': False, 'eschewed': False, 'found': False, 'envisions': False, 'brussels': False, 'keeve': False, 'premier': False, 'sharpe': False, 'yards': False, 'unequivocally': False, 'revolves': False, 'garrett': False, 'testament': False, 'hither': False, 'mincemeat': False, 'scoundrels': False, 'asses': False, 'ridiculousy': False, 'exceptionlly': False, 'battle': False, 'leonor': False, 'napalm': False, 'movie_': False, 'nita': False, 'dangerous': False, 'history': False, 'attacking': False, 'rubber': False, 'liners': False, 'collection': False, 'ballentine': False, 'indignantly': False, 'caine': False, 'diehard': False, 'doli': False, 'mardi': False, 'thrills': False, 'replenish': False, 'involve': False, 'archaic': False, 'token': False, 'benevolent': False, 'predominant': False, 'shipboard': False, 'stallone': False, 'lizzy': False, 'spear': False, 'brie': False, '19': False, 'lee': False, 'qinqin': False, 'sin': False, '_come_': False, 'irritating': False, 'senseless': False, 'cumulative': False, 'beginning': False, 'selection': False, 'childbearings': False, 'oscars': False, 'swimming': False, 'lucid': False, 'latter': False, 'hammond': False, 'scavenge': False, 'bumblebee': False, 'silver': False, 'horoscopes': False, '165': False, 'astounded': False, 'sooooo': False, 'decapitated': False, 'unconventional': False, 'beales': False, 'battleships': False, 'psyches': False, 'apparent': False, 'shirking': False, 'pacing': False, 'hats': False, 'pear': False, 'scorecard': False, 'yuk': False, 'forewarned': False, 'koji': False, 'counsellor': False, 'magnitude': False, 'diplomatic': False, 'butabi': False, 'taymor': False, 'modernization': False, 'gadgets': False, 'cormack': False, 'hearken': False, 'tiering': False, 'from': True, 'ruckus': False, 'dazzle': False, 'epidemic': False, 'blotter': False, 'withing': False, 'crackling': False, 'flashing': False, 'coens': False, 'structuring': False, 'screenwriters': False, 'public': False, 'hetero': False, 'static': False, 'phases': False, 'soldering': False, 'safety': False, '@': False, 'tango': False, 'makes': True, 'estrogen': False, 'sudan': False, 'uncut': False, 'fairly': False, 'barrymore': False, 'shapeless': False, 'thunderclaps': False, 'radiation': False, 'ravine': False, 'extravertedness': False, 'basque': False, 'precluded': False, 'narcissistically': False, 'schow': False, 'sitations': False, 'scaramanga': False, 'forlorn': False, 'fowler': False, 'brutalized': False, 'viewers': False, 'bowen': False, 'mawkish': False, 'payoff': False, 'troublemaker': False, 'discovering': False, 'unforgiveably': False, 'lisp': False, 'furrow': False, 'tackled': False, 'birdhouse': False, '_patlabor': False, 'ardent': False, 'hubert': False, 'missouri': False, 'cynics': False, 'hateful': False, 'mattes': False, 'bruklin': False, 'duane': False, 'touchingly': False, 'hommage': False, 'faithfully': False, 'romulus': False, 'den': False, 'ch': False, 'litefoot': False, 'twistet': False, 'simcha': False, 'virgo': False, 'expelling': False, 'assumption': False, 'examinations': False, 'hams': False, 'terrifically': False, 'disapprobation': False, 'thoughtfulness': False, 'reassess': False, 'lenient': False, 'power': False, 'donner': False, 'knows': False, 'istvan': False, 'nostalgia': False, 'subtly': False, 'exits': False, 'scoffs': False, 'bb': False, 'renew': False, 'entrapment': False, 'atrice': False, 'lams': False, 'simone': False, 'loitered': False, 'award': False, 'realisation': False, 'bartleby': False, 'interfering': False, 'leon': False, 'bloodier': False, 'laugh': False, 'ro': False, 'shadowy': False, 'adequately': False, 'clandestinely': False, 'fatter': False, 'bacchanal': False, 'bias': False, 'cutedom': False, 'hopes': False, 'brinkley': False, 'herding': False, 'mugging': False, 'primae': False, 'rumours': False, 'easter': False, 'benefit': False, 'awaken': False, 'schizophrenia': False, 'scrawny': False, 'fuelled': False, 'bedmates': False, 'blessing': False, 'exorcist': False, 'primordial': False, '70s': False, 'stringy': False, 'brainwash': False, 'capper': False, '_his_': False, 'videodrome': False, 'vincenzo': False, 'dohlen': False, 'firestorm': False, 'yell': False, 'quote': False, 'kaleidoscopic': False, 'wyle': False, 'trickier': False, 'cole': False, 'slab': False, 'outstandingly': False, 'barker': False, 'refuge': False, 'scale': False, 'anticlimatic': False, 'disturbs': False, 'assassinates': False, 'slapstick': False, 'villainous': False, 'attired': False, 'sadist': False, 'safeties': False, 'bankrupt': False, 'giggle': False, 'pacifistic': False, 'rocky': False, 'pupil': False, 'rouge': False, 'stipulated': False, 'twit': False, 'pacific': False, 'title': False, 'bait': False, 'promoters': False, 'nordern': False, 'reported': False, 'mcglory': False, 'repartee': False, 'justifies': False, 'superviolent': False, 'inventiveness': False, 'denial': False, 'japanese': False, 'harris': False, 'mitchum': False, 'herrings': False, 'enigmatic': False, 'volunteering': False, 'country': False, 'rooney': False, 'prioritized': False, 'rounding': False, 'apartments': False, 'crystal': False, 'flashy': False, 'parrish': False, 'sacrifice': False, 'prison': False, 'lobster': False, 'classified': False, 'inevitably': False, 'eagles': False, 'unexploitive': False, 'ditzy': False, 'specific': False, 'truly': False, 'funicello': False, 'rhetorically': False, 'servo': False, 'ex': False, 'goblins': False, 'devils': False, 'reptile': False, 'jezelle': False, 'impaling': False, 'coaxed': False, 'gamesmanship': False, 'beaker': False, 'invents': False, '_fantastic_': False, 'aumont': False, 'invincible': False, 'interconnectedness': False, 'freewill': False, 'offensively': False, 'hops': False, 'iced': False, 'spoilers': False, 'melvon': False, 'ted': False, 'offstage': False, 'positing': False, 'defacing': False, 'noted': False, 'social': False, 'suspensful': False, 'skillfully': False, 'trudging': False, 'ampbell': False, 'wad': False, 'columbo': False, 'orphaned': False, 'lingering': False, 'tapert': False, 'attachment': False, 'ditching': False, 'molesters': False, 'allusion': False, 'institute': False, 'chi': False, 'watkin': False, 'egotistical': False, 'viciousness': False, 'patricia': False, 'typist': False, 'investigating': False, 'overplotting': False, 'shoestring': False, 'rethought': False, 'aquits': False, 'astute': False, 'whatnot': False, 'rolled': False, 'traitorous': False, 'taj': False, 'voracious': False, 'fabricates': False, 'oil': False, 'nauseatingly': False, 'guises': False, 'luncheon': False, 'do': True, 'jeffrey': False, 'tarsem': False, 'felines': False, 'roofs': False, 'calls': False, 'chomp': False, 'deployment': False, 'deprive': False, 'testicle': False, 'inadequacies': False, 'claw': False, 'zoo': False, 'bayou': False, 'awoken': False, 'baily': False, 'breathlessly': False, 'newmar': False, 'haim': False, 'thiefs': False, 'hagen': False, '_hard_ware': False, 'mentality': False, 'udall': False, 'guarantee': False, 'kira': False, 'splice': False, 'weathers': False, 'broad': False, 'fullyloaded': False, 'mcgillis': False, 'fahey': False, 'coolly': False, 'kissinger': False, 'figgis': False, 'tents': False, 'successfuly': False, 'daring': False, 'major': False, 'sniffs': False, 'unmitigated': False, 'espousing': False, 'maroon': False, 'percy': False, 'epsode': False, 'readouts': False, 'laila': False, 'beads': False, 'miscasting': False, 'rampaging': False, 'naseeruddin': False, 'losing': False, 'overdrive': False, 'foreshadowing': False, 'whetted': False, 'protestations': False, 'kickback': False, 'regards': False, 'dwarf': False, 'burner': False, 'victimizer': False, 'heretic': False, 'landlord': False, 'conserving': False, 'oz': False, 'hepburn': False, 'mexico': False, 'losely': False, 'giamatti': False, 'pitting': False, 'suggestiveness': False, 'dawn': False, 'deserts': False, 'entered': False, 'senor': False, 'chickens': False, 'makers': False, 'bond': False, 'shrewd': False, 'negotiations': False, 'unoriginal': False, 'coma': False, 'camping': False, 'rennie': False, 'messiah': False, 'strict': False, 'placating': False, 'multiply': False, 'lush': False, 'jb': False, 'joes': False, 'seekers': False, 'shadyac': False, 'supporting': False, 'applaud': True, 'centering': False, 'tyrany': False, 'delectable': False, '15th': False, 'hank': False, 'backer': False, 'mapped': False, 'juba': False, 'sanity': False, 'toe': False, 'intrusions': False, 'heightened': False, 'assassinated': False, 'telephone': False, 'creedence': False, 'speeding': False, 'dave': False, 'tumbles': False, 'morphing': False, 'esmerelda': False, 'flops': False, 'concierge': False, 'legitimacy': False, 'celine': False, 'mikel': False, 'toppling': False, 'guerra': False, 'conglomerate': False, 'sportsmanship': False, 'friendliest': False, 'yeager': False, 'clothing': False, 'factored': False, 'kidnaped': False, 'cherie': False, 'scaffold': False, 'embarassing': False, 'sargeant': False, 'descendant': False, 'mommas': False, 'tonite': False, 'indecipherable': False, 'optometrist': False, 'incorporate': False, 'nastier': False, 'peaceful': False, 'nations': False, 'starlets': False, 'villain': False, 'devise': False, 'fished': False, 'vansihes': False, 'shipped': False, 'tippi': False, 'accentuate': False, 'breathable': False, 'christian': False, 'fakery': False, 'blocks': False, 'rosemary': False, 'congregation': False, 'faulty': False, 'recreate': False, 'butterfly': False, 'editorial': False, 'unnecessary': False, 'mcnugent': False, 'pill': False, 'triangular': False, 'ignorant': False, 'conjure': False, 'approachment': False, 'ribbon': False, 'dabbles': False, 'statement': False, 'imbeciles': False, 'showings': False, 'petulant': False, 'substance': False, 'hides': False, 'sitch': False, 'hurl': False, 'foch': False, 'trial': False, 'massaging': False, 'schematic': False, 'teleplay': False, 'hat': False, 'olympic': False, 'cartoons': False, 'holidays': False, 'lascivious': False, '747s': False, 'casablanca': False, 'processed': False, 'burstyn': False, 'oath': False, 'troupe': False, 'buds': False, 'heald': False, 'begins': False, 'hoover': False, 'ni': False, 'benignly': False, 'vicariously': False, 'bottoming': False, 'dissolved': False, 'trunks': False, 'crunch': False, 'emmanuel': False, 'messengers': False, 'doted': False, 'unprintable': False, 'conceptual': False, 'denied': False, 'wilder': False, 'watergate': False, 'comanche': False, 'cinematically': False, 'sublime': False, 'laserman': False, 'cherry': False, 'considered': False, 'neatness': False, 'priviledge': False, 'innuendo': False, 'pirahna': False, 'buzzsaw': False, 'mary': False, 'ultraman': False, 'cinderella': False, 'dangle': False, 'pornogrpahy': False, 'oreo': False, 'toothpaste': False, 'breathless': False, 'sculptor': False, 'colours': False, 'korshunov': False, 'plagiarist': False, 'ruthlessness': False, 'falwells': False, 'omnipotent': False, 'ramis': False, 'helm': False, 'armor': False, 'halperin': False, 'fe': False, 'quell': False, 'willard': False, 'contributors': False, 'network': False, 'sesame': False, 'headlining': False, 'difilippo': False, 'vampire': False, 'siblings': False, 'dethrones': False, 'passing': False, 'lowlife': False, 'conceit': False, 'chariot': False, 'bows': False, 'suviving': False, 'brasco': False, 'dissipate': False, 'tafkap': False, 'tile': False, 'captor': False, 'das': False, 'deserving': False, 'identically': False, 'expatriates': False, 'partygoer': False, 'incognito': False, 'clueless': False, 'isacsson': False, 'overplays': False, 'schulz': False, 'raiders': False, 'slugs': False, 'longingly': False, 'examining': False, 'dispensing': False, 'lifeline': False, 'inuits': False, 'cello': False, 'slap': False, 'envoke': False, \"'--\": False, 'jenna': False, 'irrationality': False, 'conservationist': False, 'nothing': False, 'avocation': False, 'assets': False, 'rosie': False, 'carnage': False, 'machine': False, 'storh': False, 'open': False, 'pedlar': False, 'reappearance': False, 'stipulate': False, 'compatible': False, 'sibling': False, 'glow': False, 'pines': False, 'oneida': False, 'personifies': False, 'smugglers': False, 'heath': False, 'pilot': False, 'convince': False, 'tailor': False, 'prudent': False, 'humanoids': False, 'residents': False, 'ents': False, 'wanderlusting': False, 'professorship': False, 'responsibility': False, 'heretical': False, 'tumbling': False, 'dotted': False, 'convoluted': False, 'compromised': False, 'bass': False, '103': False, 'chorus': False, 'hrundi': False, 'friggin': False, 'renenged': False, 'interrogator': False, 'torrent': False, 'peeking': False, 'porch': False, 'ziembicki': False, 'outsmart': False, 'checkmate': False, 'heavies': False, 'catagory': False, 'stempel': False, 'affords': False, 'josu': False, 'pedophilia': False, 'rohde': False, 'obscura': False, 'glebas': False, 'zallian': False, 'disliking': False, 'sarita': False, 'androgonys': False, 'minimizing': False, 'islamic': False, 'surrandon': False, 'bucketsful': False, 'infidelities': False, 'tso': False, 'jip': False, 'zelweggar': False, 'rightfully': False, 'slam': False, 'surreptitiously': False, 'apprehend': False, 'carpark': False, 'ashau': False, 'disciple': False, 'chutes': False, 'llosa': False, 'hos': False, 'deploying': False, 'dennison': False, 'uninterestingly': False, 'elaborating': False}\n"
     ]
    }
   ],
   "source": [
    "print(find_features(movie_reviews.words('neg/cv000_29416.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_set = [(find_features(rev), category) for (rev, category) in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 13 : Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = feature_set[:1900]\n",
    "test = feature_set[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of naive bayes :  69.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of naive bayes : \", (nltk.classify.accuracy(classifiers, test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  denial = True              pos : neg    =      7.7 : 1.0\n",
      "                  subtly = True              pos : neg    =      5.7 : 1.0\n",
      "                 regards = True              pos : neg    =      5.7 : 1.0\n",
      "               collector = True              pos : neg    =      5.7 : 1.0\n",
      "              rightfully = True              pos : neg    =      5.0 : 1.0\n",
      "              unoriginal = True              neg : pos    =      4.7 : 1.0\n",
      "          anthropologist = True              neg : pos    =      4.3 : 1.0\n",
      "                   spins = True              pos : neg    =      4.3 : 1.0\n",
      "            terrifically = True              pos : neg    =      4.3 : 1.0\n",
      "                  wilder = True              pos : neg    =      4.3 : 1.0\n",
      "                  rubber = True              neg : pos    =      4.2 : 1.0\n",
      "              skillfully = True              pos : neg    =      4.1 : 1.0\n",
      "                peaceful = True              pos : neg    =      3.9 : 1.0\n",
      "                 carnage = True              neg : pos    =      3.9 : 1.0\n",
      "           cinematically = True              pos : neg    =      3.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifiers.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
